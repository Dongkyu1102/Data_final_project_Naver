{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dongkyu1102/Data_final_project_Naver/blob/main/smartstore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngh9hp0avy0-"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import re\n",
        "from selenium import webdriver # 브라우저를 조작하는 모듈\n",
        "from selenium.webdriver.chrome.service import Service # 크롬 드라이버의 시작과 중지를 담당하는 클래스\n",
        "from selenium.webdriver.common.by import By # 엘리먼트를 어떤 방식으로 선택할 지에 대한 상수\n",
        "from webdriver_manager.chrome import ChromeDriverManager # 크롬 드라이버를 관리\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from selenium.webdriver import ActionChains\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.keys import Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EJk-Lomvy1C"
      },
      "outputs": [],
      "source": [
        "def all_review(soup): # 모든 리뷰 갯수 찾아오는 함수\n",
        "    review = soup.find('span', attrs={'class':'_3HJHJjSrNK'}).text # soup에서 찾아라. <span class=\"_3HJHJjSrNK\">20,813</span>를 여기서 text(20,813)만 가져와라\n",
        "    review = int(review.replace(',', '')) # ,날리고 정수만 남겨서 저장\n",
        "    return review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zo87B_Avy1D"
      },
      "outputs": [],
      "source": [
        "def review_per_page(soup): # 하나의 페이지에 있는 리뷰(20개) 찾아오는 함수\n",
        "    content= soup.find_all('div', attrs={'class':'YEtwtZFLDz'}) # find_all을 씀으로써 순서대로 20개의 댓글 찾아옴\n",
        "    return len(content) # 갯수 반환(마지막 페이지에서만 갯수가 다를 수 있음!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcc18AGyvy1D"
      },
      "outputs": [],
      "source": [
        "def next_click(driver):\n",
        "    driver.find_element(By.CSS_SELECTOR, '#REVIEW > div > div._180GG7_7yx > div.cv6id6JEkg > div > div > a.fAUKm1ewwo._2Ar8-aEUTq').click()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu6MJSiLvy1E"
      },
      "outputs": [],
      "source": [
        "def review_click(driver): # 리뷰 클릭 동작하는 함수\n",
        "    selector = \"a[href='#'][class='_11xjFby3Le N=a:tab.review']\" # 리뷰 버튼 위치를 selector로 지정\n",
        "    button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector)))\n",
        "    button.click()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHt3y0WRvy1F"
      },
      "outputs": [],
      "source": [
        "def data_collect(soup, i):\n",
        "    # 댓글 본문 수집\n",
        "    content= soup.find_all('div', attrs={'class':'YEtwtZFLDz'})[i].text\n",
        "    content = content.replace('\\n', ' ')\n",
        "\n",
        "    # 평점 수집\n",
        "    score = soup.select('div._1YShY6EQ56 > div > div > div > em._15NU42F3kT')[i].text\n",
        "    score = int(score)\n",
        "\n",
        "    # 날짜 수집\n",
        "    date = soup.select('div._2FmJXrTVEX > span._3QDEeS6NLn')[i].text\n",
        "\n",
        "    # 옵션 수집\n",
        "    option = soup.select('div._14FigHP3K8')[i] # 옵션 + 평가(=특징)까지 같이 포함되어 있는 경로\n",
        "    # extract이 pop함수와 비슷하다고 생각하시면 편합니다. 하위 태그인 dl을 반환과 동시에 삭제하는 함수입니다.\n",
        "    try:\n",
        "        satis = option.find('dl').extract()\n",
        "    except:\n",
        "        pass\n",
        "    option = option.text\n",
        "\n",
        "    # 평가 수집\n",
        "    satis_list = []\n",
        "    try:\n",
        "        for j in range(len(satis.select('dt'))): # satis에 들어간 태그 안에 dt(=평가(헤어,세정력,두피 등))가 몇 개 있는지\n",
        "            text = satis.select('dt')[j].text +'_'+ satis.select('dd')[j].text\n",
        "            satis_list.append(text)\n",
        "    except:\n",
        "        text = ''\n",
        "        satis_list.append(text)\n",
        "    data = [content, score, date, option, satis_list]\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwIMOYTcvy1G"
      },
      "outputs": [],
      "source": [
        "url_list = ['https://smartstore.naver.com/beautyflex/products/5381572112?NaPm=ct%3Dlm9xlkrc%7Cci%3Dda27006983e50fd5adccc65fa291e87b122749a5%7Ctr%3Dslsl%7Csn%3D1133061%7Chk%3D494696a747bde4e31bbc9badc652342d17560924']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "80d3c6606cb14901b3bbfe630be4d190",
            "fab1c82c35e442019db2b99fb57d7b4f"
          ]
        },
        "id": "gPUrvlf9vy1G",
        "outputId": "c694eb99-e8b1-41e6-b9ab-d2b5dd022bca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80d3c6606cb14901b3bbfe630be4d190",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "outer:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fab1c82c35e442019db2b99fb57d7b4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "inner:   0%|          | 0/270 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--start-maximized') # 전체 화면\n",
        "options.add_argument(\"--incognito\") # 시크릿 모드\n",
        "driver = webdriver.Chrome(\n",
        "    service=Service(ChromeDriverManager().install()),\n",
        "    options=options\n",
        ")\n",
        "\n",
        "for url in tqdm(url_list, desc=\"outer\", position=0):\n",
        "    driver.get(url)\n",
        "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"a[href='#'][class='_11xjFby3Le N=a:tab.review']\")))\n",
        "    # WebDriverWait를 통해 driver를 최대 10초동안 기다린다.\n",
        "    # 언제까지? -> ID가 \"a[href='#'][class='_11xjFby3Le N=a:tab.review']\" 인 엘리먼트가 나올 때까지\n",
        "    review_click(driver) # 리뷰 버튼 클릭(이 버튼을 눌러야 리뷰들이 로딩됨)\n",
        "    driver.find_element(By.CSS_SELECTOR, 'body').send_keys(Keys.PAGE_DOWN)\n",
        "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.YEtwtZFLDz\")))\n",
        "    # WebDriverWait를 통해 driver를 최대 10초동안 기다린다.\n",
        "    # 언제까지? -> ID가 \"div.YEtwtZFLDz\" 인 엘리먼트가 나올때까지(해당 엘리먼트는 '댓글'의 위치. 즉, 한 페이지에 20개의 동일한 엘리먼트가 존재)\n",
        "    html = driver.page_source # 위의 작업이 수행된 후 해당 접속 사이트 url 정보 가져옴(html로 변수 지정)\n",
        "    soup = BeautifulSoup(html, 'lxml') # html(변수)를 통해 가져온 HTML 문서를 lxml 파서를 통해서 BeautifulSoup 객체로 만들어줌\n",
        "\n",
        "    review = all_review(soup)\n",
        "\n",
        "    page_num = (review // 20) + 1\n",
        "    result = []\n",
        "    # 1페이지 수집\n",
        "    for i in range(review_per_page(soup)):\n",
        "        data = data_collect(soup, i)\n",
        "        result.append(data)\n",
        "\n",
        "    # 2페이지 부터 수집\n",
        "    for _ in tqdm(range(page_num), desc='inner', position=1):\n",
        "        try:\n",
        "            next_click(driver)\n",
        "        except:\n",
        "            break\n",
        "        time.sleep(0.1)\n",
        "        html = driver.page_source\n",
        "        soup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "        for j in range(review_per_page(soup)):\n",
        "            data = data_collect(soup, j)\n",
        "            result.append(data)\n",
        "\n",
        "            # time.sleep(0.3)\n",
        "\n",
        "    results_df = pd.DataFrame(result)\n",
        "    results_df.columns = ['content', 'score', 'date', 'option', 'satis_list']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqRfJLw8vy1I"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnrVGyuNvy1I"
      },
      "outputs": [],
      "source": [
        "results_df.to_csv('C:/Users/.csv', index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT376z36vy1J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}